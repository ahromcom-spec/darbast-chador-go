import { useState, useEffect, useRef, useCallback } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { useToast } from '@/hooks/use-toast';
import { Send, MessageCircle, User, UserCheck, Mic, Square, Loader2 } from 'lucide-react';
import { useAuth } from '@/contexts/AuthContext';

interface Message {
  id: string;
  order_id: string;
  user_id: string;
  message: string;
  is_staff: boolean;
  created_at: string;
  audio_path?: string;
  profiles?: {
    full_name: string;
  };
}

interface OrderChatProps {
  orderId: string;
  orderStatus: string;
}

export default function OrderChat({ orderId, orderStatus }: OrderChatProps) {
  const [messages, setMessages] = useState<Message[]>([]);
  const [newMessage, setNewMessage] = useState('');
  const [loading, setLoading] = useState(false);
  const [isStaff, setIsStaff] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const { toast } = useToast();
  const { user } = useAuth();

  // Voice recording state
  const [isRecording, setIsRecording] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [isUploading, setIsUploading] = useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  // Voice message playback (native player)
  const [audioUrlByMessageId, setAudioUrlByMessageId] = useState<Record<string, string>>({});
  const [audioUrlLoadingByMessageId, setAudioUrlLoadingByMessageId] = useState<Record<string, boolean>>({});

  // Check user role
  useEffect(() => {
    if (!user) return;
    
    const checkRole = async () => {
      const { data } = await supabase
        .from('user_roles')
        .select('role')
        .eq('user_id', user.id)
        .in('role', ['admin', 'ceo', 'general_manager', 'sales_manager', 'scaffold_executive_manager', 'executive_manager_scaffold_execution_with_materials'])
        .maybeSingle();
      setIsStaff(!!data);
    };
    
    checkRole();
  }, [user]);

  // Fetch messages
  useEffect(() => {
    if (!orderId) return;
    
    fetchMessages();
    
    const channel = supabase
      .channel(`order-messages-${orderId}`)
      .on(
        'postgres_changes',
        {
          event: 'INSERT',
          schema: 'public',
          table: 'order_messages',
          filter: `order_id=eq.${orderId}`
        },
        () => fetchMessages()
      )
      .subscribe();

    return () => {
      supabase.removeChannel(channel);
    };
  }, [orderId]);

  const fetchMessages = async () => {
    try {
      const { data: messagesData, error: messagesError } = await supabase
        .from('order_messages')
        .select('*')
        .eq('order_id', orderId)
        .order('created_at', { ascending: true });

      if (messagesError) throw messagesError;

      if (messagesData && messagesData.length > 0) {
        const userIds = [...new Set(messagesData.map(m => m.user_id))];
        const { data: profilesData } = await supabase
          .from('profiles')
          .select('user_id, full_name')
          .in('user_id', userIds);

        const profilesMap = new Map(
          profilesData?.map(p => [p.user_id, p]) || []
        );

        setMessages(messagesData.map(msg => ({
          ...msg,
          profiles: profilesMap.get(msg.user_id)
        })));
      } else {
        setMessages([]);
      }
    } catch (error) {
      console.error('Error fetching messages:', error);
    }
  };

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  const sendMessage = async () => {
    if (!newMessage.trim() || !user) return;

    setLoading(true);
    try {
      const { error } = await supabase
        .from('order_messages')
        .insert([{
          order_id: orderId,
          user_id: user.id,
          message: newMessage.trim(),
          is_staff: isStaff
        }]);

      if (error) throw error;

      setNewMessage('');
      scrollToBottom();
      toast({ title: 'Ù¾ÛŒØ§Ù… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯' });
    } catch (error: any) {
      toast({
        title: 'Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…',
        description: error.message,
        variant: 'destructive'
      });
    } finally {
      setLoading(false);
    }
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  };

  // Check microphone permission status
  const checkMicrophonePermission = useCallback(async (): Promise<'granted' | 'denied' | 'prompt'> => {
    try {
      if (navigator.permissions) {
        const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        return result.state;
      }
      return 'prompt';
    } catch {
      return 'prompt';
    }
  }, []);

  // Start recording voice
  const startRecording = useCallback(async () => {
    try {
      console.log('Starting voice recording...');
      
      // First check if microphone permission is already denied
      const permissionState = await checkMicrophonePermission();
      console.log('Permission state:', permissionState);
      
      if (permissionState === 'denied') {
        toast({
          title: 'Ø¯Ø³ØªØ±Ø³ÛŒ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø±Ø¯ Ø´Ø¯Ù‡ Ø§Ø³Øª',
          description: 'Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø±ÙˆØ±Ú¯Ø± Ø®ÙˆØ¯ØŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³Ø§ÛŒØª ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯. Ø³Ù¾Ø³ ØµÙØ­Ù‡ Ø±Ø§ Ø±ÙØ±Ø´ Ú©Ù†ÛŒØ¯.',
          variant: 'destructive',
          duration: 8000
        });
        return;
      }

      // Request microphone access
      console.log('Requesting microphone access...');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      console.log('Microphone access granted');
      streamRef.current = stream;
      
      // Choose the best supported format for maximum compatibility
      let mimeType = '';
      const mimeTypes = [
        'audio/mp4',       // Best for iOS/Safari
        'audio/webm;codecs=opus',  // Best for Chrome/Firefox
        'audio/webm',
        'audio/ogg;codecs=opus',
        'audio/ogg',
        ''  // Let browser decide
      ];
      
      for (const type of mimeTypes) {
        if (!type || MediaRecorder.isTypeSupported(type)) {
          mimeType = type;
          console.log('Selected mimeType:', mimeType || 'default');
          break;
        }
      }
      
      console.log('Creating MediaRecorder with mimeType:', mimeType || 'browser default');
      const mediaRecorder = mimeType 
        ? new MediaRecorder(stream, { mimeType })
        : new MediaRecorder(stream);
      
      console.log('MediaRecorder created, actual mimeType:', mediaRecorder.mimeType);
      
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        console.log('Data available:', event.data.size, 'bytes');
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onerror = (event) => {
        console.error('MediaRecorder error:', event);
      };

      mediaRecorder.start(500); // Collect data every 500ms
      console.log('Recording started');
      setIsRecording(true);
      setRecordingDuration(0);

      // Timer for duration display (max 3 minutes)
      recordingTimerRef.current = setInterval(() => {
        setRecordingDuration(prev => {
          if (prev >= 179) {
            stopRecording();
            toast({ title: 'Ø­Ø¯Ø§Ú©Ø«Ø± Ø²Ù…Ø§Ù† Ø¶Ø¨Ø·: Û³ Ø¯Ù‚ÛŒÙ‚Ù‡' });
            return 180;
          }
          return prev + 1;
        });
      }, 1000);

    } catch (error: any) {
      console.error('Microphone error:', error);
      
      let errorMessage = 'Ù„Ø·ÙØ§Ù‹ Ø¯Ø³ØªØ±Ø³ÛŒ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø±Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø±ÙˆØ±Ú¯Ø± ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯';
      
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        errorMessage = 'Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø±Ø¯ Ø´Ø¯. Ø¨Ø±Ø§ÛŒ Ø¶Ø¨Ø· ØµØ¯Ø§ØŒ Ù„Ø·ÙØ§Ù‹ Ø±ÙˆÛŒ Ø¢ÛŒÚ©ÙˆÙ† Ù‚ÙÙ„ Ø¯Ø± Ù†ÙˆØ§Ø± Ø¢Ø¯Ø±Ø³ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯ Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø±Ø§ ÙØ¹Ø§Ù„ Ù†Ù…Ø§ÛŒÛŒØ¯.';
      } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
        errorMessage = 'Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ø§ØªØµØ§Ù„ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø¨Ù‡ Ø¯Ø³ØªÚ¯Ø§Ù‡ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯.';
      } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
        errorMessage = 'Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.';
      }
      
      toast({
        title: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†',
        description: errorMessage,
        variant: 'destructive',
        duration: 8000
      });
    }
  }, [toast, checkMicrophonePermission]);

  // Stop recording and upload
  const stopRecording = useCallback(async () => {
    console.log('Stopping recording...');
    if (!mediaRecorderRef.current || !user) {
      console.log('No mediaRecorder or user');
      return;
    }

    // Clear timer
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }

    const mediaRecorder = mediaRecorderRef.current;
    const recordedMimeType = mediaRecorder.mimeType || 'audio/webm';
    console.log('Recorded mimeType:', recordedMimeType);
    
    setIsRecording(false);
    setIsUploading(true);

    // Create a promise to wait for recording to stop
    const recordingComplete = new Promise<void>((resolve) => {
      mediaRecorder.onstop = () => {
        console.log('MediaRecorder stopped');
        // Stop all tracks
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => track.stop());
          streamRef.current = null;
        }
        resolve();
      };
    });

    mediaRecorder.stop();
    await recordingComplete;

    // Small delay to ensure all data is collected
    await new Promise(resolve => setTimeout(resolve, 300));

    try {
      console.log('Audio chunks collected:', audioChunksRef.current.length);
      
      // Create blob from chunks - use the recorded mimeType
      const audioBlob = new Blob(audioChunksRef.current, { type: recordedMimeType });
      
      console.log('Audio blob created. Size:', audioBlob.size, 'Type:', audioBlob.type);

      if (audioBlob.size < 500) {
        toast({ title: 'Ø¶Ø¨Ø· ØµÙˆØªÛŒ Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª', variant: 'destructive' });
        setIsUploading(false);
        return;
      }

      // Determine file extension from mime type
      let extension = 'webm';
      if (recordedMimeType.includes('mp4')) extension = 'mp4';
      else if (recordedMimeType.includes('ogg')) extension = 'ogg';
      else if (recordedMimeType.includes('mpeg') || recordedMimeType.includes('mp3')) extension = 'mp3';
      else if (recordedMimeType.includes('aac')) extension = 'aac';

      const fileName = `${orderId}/${user.id}/${Date.now()}.${extension}`;
      
      console.log('Uploading to voice-messages bucket:', fileName);

      // Upload to storage
      const { data: uploadData, error: uploadError } = await supabase.storage
        .from('voice-messages')
        .upload(fileName, audioBlob, {
          contentType: recordedMimeType,
          cacheControl: '3600',
          upsert: false
        });

      if (uploadError) {
        console.error('Storage upload error:', uploadError);
        throw uploadError;
      }

      console.log('Upload success, path:', uploadData.path);

      // Create message record
      const { error: messageError } = await supabase
        .from('order_messages')
        .insert([{
          order_id: orderId,
          user_id: user.id,
          message: 'ğŸ¤ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ',
          is_staff: isStaff,
          audio_path: uploadData.path
        }]);

      if (messageError) {
        console.error('Message insert error:', messageError);
        throw messageError;
      }

      console.log('Voice message saved successfully');
      toast({ title: 'Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯ âœ“' });
      scrollToBottom();

    } catch (error: any) {
      console.error('Upload/save error:', error);
      toast({
        title: 'Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ',
        description: error.message || 'Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯',
        variant: 'destructive'
      });
    } finally {
      setIsUploading(false);
      setRecordingDuration(0);
      audioChunksRef.current = [];
    }
  }, [user, orderId, isStaff, toast]);

  // Resolve voice message URLs (signed URL preferred)
  const fetchVoiceMessageUrl = useCallback(async (audioPath: string): Promise<string | null> => {
    const { data, error } = await supabase.storage
      .from('voice-messages')
      .createSignedUrl(audioPath, 86400); // 24h expiry

    if (!error && data?.signedUrl) return data.signedUrl;

    const { data: publicData } = supabase.storage
      .from('voice-messages')
      .getPublicUrl(audioPath);

    return publicData?.publicUrl || null;
  }, []);

  const resolveAudioUrlForMessage = useCallback(
    async (messageId: string, audioPath: string, opts?: { silent?: boolean }) => {
      if (!audioPath) return null;

      setAudioUrlLoadingByMessageId((prev) => ({ ...prev, [messageId]: true }));

      try {
        const url = await fetchVoiceMessageUrl(audioPath);
        if (!url) throw new Error('Ø¢Ø¯Ø±Ø³ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯');

        setAudioUrlByMessageId((prev) => ({ ...prev, [messageId]: url }));
        return url;
      } catch (error: any) {
        console.error('Error resolving voice message url:', error);

        if (!opts?.silent) {
          toast({
            title: 'Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØµØ¯Ø§',
            description: error?.message || 'ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ù†ÛŒØ³Øª.',
            variant: 'destructive',
          });
        }

        return null;
      } finally {
        setAudioUrlLoadingByMessageId((prev) => {
          const next = { ...prev };
          delete next[messageId];
          return next;
        });
      }
    },
    [fetchVoiceMessageUrl, toast]
  );

  // Preload signed URLs so the user can use the phone's native audio controls reliably
  useEffect(() => {
    const voiceMessages = messages.filter((m) => !!m.audio_path);
    if (voiceMessages.length === 0) return;

    for (const m of voiceMessages) {
      if (!m.audio_path) continue;
      if (audioUrlByMessageId[m.id]) continue;
      if (audioUrlLoadingByMessageId[m.id]) continue;
      resolveAudioUrlForMessage(m.id, m.audio_path, { silent: true });
    }
  }, [messages, audioUrlByMessageId, audioUrlLoadingByMessageId, resolveAudioUrlForMessage]);

  const formatDuration = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  // Don't show chat for closed/rejected orders
  if (['rejected', 'closed'].includes(orderStatus)) {
    return null;
  }

  return (
    <Card>
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <MessageCircle className="h-5 w-5" />
          Ú¯ÙØªÚ¯Ùˆ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-4">
        {/* Messages list */}
        <div className="max-h-96 overflow-y-auto space-y-3 p-4 bg-muted/30 rounded-lg">
          {messages.length === 0 ? (
            <div className="text-center text-muted-foreground py-8">
              <MessageCircle className="h-12 w-12 mx-auto mb-2 opacity-50" />
              <p>Ù‡Ù†ÙˆØ² Ù¾ÛŒØ§Ù…ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª</p>
              <p className="text-sm mt-1">Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØªØŒ Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯</p>
            </div>
          ) : (
            messages.map((msg) => (
              <div
                key={msg.id}
                className={`flex gap-3 ${msg.user_id === user?.id ? 'flex-row-reverse' : 'flex-row'}`}
              >
                <div
                  className={`flex-shrink-0 h-8 w-8 rounded-full flex items-center justify-center ${
                    msg.is_staff ? 'bg-primary text-primary-foreground' : 'bg-muted text-muted-foreground'
                  }`}
                >
                  {msg.is_staff ? <UserCheck className="h-4 w-4" /> : <User className="h-4 w-4" />}
                </div>
                <div className={`flex-1 max-w-[70%] ${msg.user_id === user?.id ? 'text-right' : 'text-left'}`}>
                  <div
                    className={`rounded-lg p-3 ${
                      msg.user_id === user?.id
                        ? 'bg-primary text-primary-foreground'
                        : 'bg-background border'
                    }`}
                  >
                    {msg.is_staff && (
                      <div className="text-xs opacity-80 mb-1">
                        {msg.profiles?.full_name || 'Ù…Ø¯ÛŒØ±ÛŒØª'}
                      </div>
                    )}
                    
                    {/* Voice message */}
                    {msg.audio_path ? (
                      <div className="w-full">
                        {audioUrlByMessageId[msg.id] ? (
                          <div className="flex flex-col gap-2">
                            <audio
                              controls
                              preload="metadata"
                              playsInline
                              src={audioUrlByMessageId[msg.id]}
                              className="w-full max-w-[260px]"
                            />

                            <div className="flex items-center gap-3 text-xs">
                              <a
                                href={audioUrlByMessageId[msg.id]}
                                target="_blank"
                                rel="noreferrer"
                                className="text-muted-foreground underline underline-offset-4 hover:text-foreground"
                              >
                                Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ø¯Ø± Ù¾Ù„ÛŒØ± Ú¯ÙˆØ´ÛŒ
                              </a>
                              <a
                                href={audioUrlByMessageId[msg.id]}
                                download
                                className="text-muted-foreground underline underline-offset-4 hover:text-foreground"
                              >
                                Ø¯Ø§Ù†Ù„ÙˆØ¯
                              </a>
                            </div>
                          </div>
                        ) : audioUrlLoadingByMessageId[msg.id] ? (
                          <div className="flex items-center gap-2">
                            <Loader2 className="h-4 w-4 animate-spin" />
                            <span className="text-sm">Ø¯Ø±Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡Ø³Ø§Ø²ÛŒ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ...</span>
                          </div>
                        ) : (
                          <div className="flex items-center gap-2">
                            <Button
                              size="sm"
                              variant={msg.user_id === user?.id ? "secondary" : "outline"}
                              onClick={() => resolveAudioUrlForMessage(msg.id, msg.audio_path!, { silent: false })}
                            >
                              Ø¢Ù…Ø§Ø¯Ù‡Ø³Ø§Ø²ÛŒ Ù¾Ø®Ø´
                            </Button>
                            <span className="text-sm">ğŸ¤ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ</span>
                          </div>
                        )}
                      </div>
                    ) : (
                      <p className="text-sm whitespace-pre-wrap">{msg.message}</p>
                    )}
                  </div>
                  <div className="text-xs text-muted-foreground mt-1 px-1">
                    {new Date(msg.created_at).toLocaleString('fa-IR', {
                      hour: '2-digit',
                      minute: '2-digit',
                      year: 'numeric',
                      month: 'numeric',
                      day: 'numeric'
                    })}
                  </div>
                </div>
              </div>
            ))
          )}
          <div ref={messagesEndRef} />
        </div>

        {/* Message input */}
        <div className="flex gap-2">
          <Textarea
            value={newMessage}
            onChange={(e) => setNewMessage(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder="Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯..."
            className="min-h-[80px] resize-none"
            disabled={loading || isRecording || isUploading}
          />
          <div className="flex flex-col gap-2">
            <Button
              onClick={sendMessage}
              disabled={loading || !newMessage.trim() || isRecording || isUploading}
              className="flex-shrink-0"
              size="lg"
            >
              <Send className="h-4 w-4" />
            </Button>
            
            {/* Voice record button */}
            {isRecording ? (
              <Button
                onClick={stopRecording}
                variant="destructive"
                size="lg"
                className="flex-shrink-0"
                disabled={isUploading}
              >
                <Square className="h-4 w-4" />
              </Button>
            ) : isUploading ? (
              <Button
                variant="secondary"
                size="lg"
                className="flex-shrink-0"
                disabled
              >
                <Loader2 className="h-4 w-4 animate-spin" />
              </Button>
            ) : (
              <Button
                onClick={startRecording}
                variant="secondary"
                size="lg"
                className="flex-shrink-0"
                disabled={loading}
              >
                <Mic className="h-4 w-4" />
              </Button>
            )}
          </div>
        </div>

        {/* Recording indicator */}
        {isRecording && (
          <div className="flex items-center justify-center gap-2 text-destructive animate-pulse">
            <div className="h-2 w-2 rounded-full bg-destructive" />
            <span className="text-sm">Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø·... {formatDuration(recordingDuration)}</span>
          </div>
        )}

        <p className="text-xs text-muted-foreground">
          Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒØŒ Enter Ø±Ø§ ÙØ´Ø§Ø± Ø¯Ù‡ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒØŒ Ø±ÙˆÛŒ Ø¢ÛŒÚ©ÙˆÙ† Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯.
        </p>
      </CardContent>
    </Card>
  );
}
